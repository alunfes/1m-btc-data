{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFUMJDKFG2wPvCG7Z0mJet",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alunfes/1m-btc-data/blob/master/Cartpole_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60nRjjLxNznt",
        "outputId": "ef7fb754-7e95-4f03-8a57-06c7071739f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.9/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.13.1+cu116)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (0.21.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (4.13.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from stable-baselines3) (1.22.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata~=4.13->stable-baselines3) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.11->stable-baselines3) (4.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (3.0.9)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (23.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (4.39.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->stable-baselines3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.9/dist-packages (1.7.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3\n",
        "!pip install torchinfo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gym\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "7HhuASBgOM34"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "        self.Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(self.Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "Xhhms0wjN6uU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, hidden_size, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "-YzLaXuON8db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "4NXldEKArKkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the AdamW optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "hidden_size =128\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, hidden_size, n_actions).to(device)\n",
        "target_net = DQN(n_observations, hidden_size, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "m1Crk3cGq4YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = memory.Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "cDB5D9hlr1CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 300\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get it's state\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    for t in count():\n",
        "        action = select_action(state)\n",
        "        observation, reward, terminated, truncated = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "            episode_durations.append(t + 1)\n",
        "            plot_durations()\n",
        "            break\n",
        "\n",
        "print('Complete')\n",
        "plot_durations(show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "RcwPa_EPq5MN",
        "outputId": "009c736e-3f98-4b4f-ae1d-238f6814b9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e2ad1fc2356d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the policy network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Soft update of the target network's weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-80faa69e9943>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# In-place gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    163\u001b[0m                   \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                   \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adamw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    220\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "'''\n",
        "class DQNMain:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 128\n",
        "        self.gamma = 0.99\n",
        "        self.eps_start = 0.9\n",
        "        self.eps_end = 0.05\n",
        "        self.eps_decay = 1000\n",
        "        self.tau = 0.005\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        #matplot\n",
        "        plt.ion()\n",
        "        #ENV\n",
        "        self.env = gym.make(\"CartPole-v1\")\n",
        "        self.num_actions = self.env.action_space.n\n",
        "        state = self.env.reset()\n",
        "        self.num_obs = len(state)\n",
        "        #NN\n",
        "        self.hidden_size = 128\n",
        "        self.policy_net = DQN(self.num_obs, self.hidden_size, self.num_actions).to(self.device)\n",
        "        self.target_net = DQN(self.num_obs, self.hidden_size, self.num_actions).to(self.device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=1e-04, amsgrad=True)\n",
        "        self.memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "    def select_action(self, state, num_steps):\n",
        "        sample = random.random()\n",
        "        eps_threshold = self.eps_end + (self.eps_start - self.eps_end) * math.exp(-1. * num_steps / self.eps_decay)\n",
        "        if sample > eps_threshold:\n",
        "            with torch.no_grad():\n",
        "                return self.policy_net(state).max(1)[1].view(1, 1)\n",
        "        else:\n",
        "            return torch.tensor([[self.env.action_space.sample()]], device=self.device, dtype=torch.long)\n",
        "\n",
        "    def plot_durations(self, episode_durations, show_result=False):\n",
        "        plt.figure(1)\n",
        "        durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "        if show_result:\n",
        "            plt.title('Result')\n",
        "        else:\n",
        "            plt.clf()\n",
        "            plt.title('Training...')\n",
        "        plt.xlabel('Episode')\n",
        "        plt.ylabel('Duration')\n",
        "        plt.plot(durations_t.numpy())\n",
        "        # Take 100 episode averages and plot them too\n",
        "        if len(durations_t) >= 100:\n",
        "            means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "            means = torch.cat((torch.zeros(99), means))\n",
        "            plt.plot(means.numpy())\n",
        "        plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())\n",
        "\n",
        "\n",
        "    def optimize_model(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "        transitions = self.memory.sample(self.batch_size)\n",
        "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "        # detailed explanation). This converts batch-array of Transitions\n",
        "        # to Transition of batch-arrays.\n",
        "        batch = self.memory.Transition(*zip(*transitions))\n",
        "\n",
        "        # Compute a mask of non-final states and concatenate the batch elements\n",
        "        # (a final state would've been the one after which simulation ended)\n",
        "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                            batch.next_state)), device=self.device, dtype=torch.bool)\n",
        "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                    if s is not None])\n",
        "        state_batch = torch.cat(batch.state)\n",
        "        action_batch = torch.cat(batch.action)\n",
        "        reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
        "        next_state_values = torch.zeros(self.batch_size, device=self.device)\n",
        "        with torch.no_grad():\n",
        "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0]\n",
        "        expected_state_action_values = (next_state_values * self.gamma) + reward_batch\n",
        "\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # In-place gradient clipping\n",
        "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
        "        self.optimizer.step()\n",
        "        return loss\n",
        "\n",
        "    def soft_update(self, target, source, tau):\n",
        "        with torch.no_grad():\n",
        "            for target_param, param in zip(target.parameters(), source.parameters()):\n",
        "                target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
        "\n",
        "\n",
        "    def main_loop(self, num_episodes):\n",
        "        num_steps_log = []\n",
        "        \n",
        "        for i_episode in range(num_episodes):\n",
        "            state = self.env.reset()\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "            for t in count():\n",
        "                action = self.select_action(state, t)\n",
        "                observation, reward, terminated, truncated = self.env.step(action.item())\n",
        "                reward = torch.tensor([reward], device=self.device)\n",
        "                done = terminated or truncated\n",
        "\n",
        "                if terminated:\n",
        "                    next_state = None\n",
        "                else:\n",
        "                    next_state = torch.tensor(observation, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
        "                self.memory.push(state, action, next_state, reward)\n",
        "                state = next_state\n",
        "                self.optimize_model()\n",
        "\n",
        "                # Soft update of the target network's weights\n",
        "                # θ′ ← τ θ + (1 −τ )θ′\n",
        "                '''\n",
        "                target_net_state_dict = self.target_net.state_dict()\n",
        "                policy_net_state_dict = self.policy_net.state_dict()\n",
        "                for key in policy_net_state_dict:\n",
        "                    target_net_state_dict[key] = policy_net_state_dict[key]*self.tau + target_net_state_dict[key]*(1-self.tau)\n",
        "                self.target_net.load_state_dict(target_net_state_dict)\n",
        "                '''\n",
        "                self.soft_update(self.target_net, self.policy_net, self.tau)\n",
        "\n",
        "                if done:\n",
        "                    num_steps_log.append(t + 1)\n",
        "                    self.plot_durations(num_steps_log)\n",
        "                    break\n",
        "        self.plot_durations(num_steps_log, show_result=True)\n",
        "        plt.ioff()\n",
        "        plt.show()\n",
        "\n",
        "dm = DQNMain()\n",
        "dm.main_loop(300)\n",
        "'''"
      ],
      "metadata": {
        "id": "6FTSTqYIN-lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import jit, f8, i8\n",
        "from numba import njit\n",
        "from numba.experimental import jitclass\n",
        "import itertools"
      ],
      "metadata": {
        "id": "xcKUO6-ZOTKS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imKIBFr7vNey",
        "outputId": "7fd6cff0-12ec-4792-b041-8dfe21bff643"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check ticker contains in multiple ex\n",
        "def check_ticker_in_multiple_exchanges(merged_df, num_ex_kijun):\n",
        "    ex_names = list(merged_df.ex_name)\n",
        "    base = list(merged_df.base)\n",
        "    quote = list(merged_df.quote)\n",
        "    checked_tickers = []\n",
        "    num_ex_listed = []\n",
        "    for ticker in base:\n",
        "        if ticker not in checked_tickers:\n",
        "            checked_tickers.append(ticker)\n",
        "            indices_base = [i for i, x in enumerate(quote) if x == ticker]\n",
        "            indices_quote = [i for i, x in enumerate(base) if x == ticker]\n",
        "            indices_base.extend(indices_quote)\n",
        "            exs = [ex_names[i] for i in indices_base]\n",
        "            exs = list(set(exs))\n",
        "            if len(exs) >= num_ex_kijun:\n",
        "                num_ex_listed.append({'ticker':ticker, 'exs':exs})\n",
        "    target = [x['ticker'] for i, x in enumerate(num_ex_listed)]\n",
        "    result = merged_df[merged_df['base'].isin(target) | merged_df['quote'].isin(target)]\n",
        "    return result.reset_index(drop=True)\n",
        "\n",
        "'''\n",
        "exs = check_ticker_in_multiple_exchanges(merged_df, 3)\n",
        "print(exs)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3jLrKyLDxPFq",
        "outputId": "8b17fa2f-d60b-4d5f-f6d4-28d34a4d9ce0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nexs = check_ticker_in_multiple_exchanges(merged_df, 3)\\nprint(exs)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def check_sync_symbol(base_a, quote_a, base_b, quote_b):\n",
        "    sync_symbol = ('','')\n",
        "    if base_a == quote_b:\n",
        "        if quote_a != base_b:\n",
        "            sync_symbol = (base_b, quote_a)\n",
        "    elif quote_a == base_b:\n",
        "         if base_a != quote_b:\n",
        "             sync_symbol = (base_a, quote_b)\n",
        "    return sync_symbol"
      ],
      "metadata": {
        "id": "zW86UFN3xTpE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def check_all_combinations(base, quote):\n",
        "    pair_combinations = []\n",
        "    n = len(base)\n",
        "    all_combinations = np.zeros((n**2, 2), dtype=np.int64)\n",
        "    i = 0\n",
        "    for x in range(n):\n",
        "        for y in range(n):\n",
        "            all_combinations[i, 0] = x\n",
        "            all_combinations[i, 1] = y\n",
        "            i += 1\n",
        "    for i in range(len(all_combinations)):\n",
        "        base_a = base[all_combinations[i][0]]\n",
        "        quote_a = quote[all_combinations[i][0]]\n",
        "        base_b = base[all_combinations[i][1]]\n",
        "        quote_b = quote[all_combinations[i][1]]\n",
        "        pair = check_sync_symbol(base_a, quote_a, base_b, quote_b)\n",
        "        if pair != ('',''):\n",
        "            pair_combinations.append(all_combinations[i])\n",
        "            #print(total_df.iloc[d[i][0]].symbol, ' x ', total_df.iloc[d[i][1]].symbol, ' = ', pair)\n",
        "    return pair_combinations\n",
        "\n",
        "'''\n",
        "pair_combinations = check_all_combinations(list(total_df.base), list(total_df.quote))\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NmGqdKsn9Ysg",
        "outputId": "ee02e86b-4ac2-485f-a78f-2498bbe8bf36"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npair_combinations = check_all_combinations(list(total_df.base), list(total_df.quote))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pairとして成立しているものの合成後のex list, sdie list, symbol, 価格を加える。\n",
        "@jit\n",
        "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
        "    sync_data = []\n",
        "    for comb in pair_combinations:\n",
        "        a_index = comb[0]\n",
        "        b_index = comb[1]\n",
        "        a_ave_price = ave_price[a_index]\n",
        "        b_ave_price = ave_price[b_index]\n",
        "        a_vol = vol[a_index]\n",
        "        b_vol = vol[b_index]\n",
        "        a_side = side[a_index]\n",
        "        b_side = side[b_index]\n",
        "        a_symbol = base[a_index] + '/' + quote[a_index]\n",
        "        b_symbol = base[b_index] + '/' + quote[b_index]\n",
        "        symbol = check_sync_symbol(base[a_index], quote[a_index], base[b_index], quote[b_index])\n",
        "        if symbol != ('', ''):\n",
        "            sync_data.append({'ex_name': ex_name[a_index] + ',' + ex_name[b_index],\n",
        "                              'symbol': symbol[0] + '/' + symbol[1],\n",
        "                              'ave_price': a_ave_price * b_ave_price,\n",
        "                              'vol': str(a_vol) + ',' + str(b_vol),\n",
        "                              'base': symbol[0],\n",
        "                              'quote': symbol[1],\n",
        "                              'side': a_side + ',' + b_side})\n",
        "    sync_df = pd.DataFrame(sync_data)\n",
        "    return sync_df\n",
        "'''    \n",
        "sync_df = generate_df_for_pair_combinations(pair_combinations, list(total_df.ex_name), list(total_df.base), list(total_df.quote), list(total_df.ave_price), list(total_df.vol), list(total_df.side))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dzQF0vcEcaU5",
        "outputId": "ba72a572-4a86-431a-92cc-5e184caf08a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    \\nsync_df = generate_df_for_pair_combinations(pair_combinations, list(total_df.ex_name), list(total_df.base), list(total_df.quote), list(total_df.ave_price), list(total_df.vol), list(total_df.side))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.concat([total_df, sync_df], ignore_index=True).reset_index(drop=True)\n",
        "final_df[\"symbol\"] = final_df[\"symbol\"].str.replace(\"USDT|USDC|BUSD\", \"USD\", regex=True)\n",
        "final_df = final_df.sort_values(\"symbol\")\n",
        "price_diff_ratio = []\n",
        "current_symbol = ''\n",
        "for i in range(len(final_df)):\n",
        "    if current_symbol != final_df.iloc[i].symbol:\n",
        "        \n"
      ],
      "metadata": {
        "id": "XY1Ajw13qF-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# symbol列でグループ化する\n",
        "grouped = final_df.groupby(\"symbol\")\n",
        "\n",
        "# 各グループに対して、最大値と最小値を特定し、計算する\n",
        "results = []\n",
        "for name, group in grouped:\n",
        "    vol_min, vol_max = group[\"vol\"].str.split(\",\", expand=True).astype(float).agg([\"min\", \"max\"])\n",
        "    ave_price = group[\"ave_price\"].mean()\n",
        "    diff = (vol_max - vol_min) / vol_max\n",
        "    min_index = group.loc[group[\"vol\"].str.contains(str(vol_min.values[0]))].index[0]\n",
        "    max_index = group.loc[group[\"vol\"].str.contains(str(vol_max.values[0]))].index[0]\n",
        "    results.append((name, vol_min.values[0], vol_max.values[0], diff.values[0], ave_price, min_index, max_index))\n",
        "\n",
        "# 結果をDataFrameに変換して表示する\n",
        "df_results = pd.DataFrame(results, columns=[\"symbol\", \"vol_min\", \"vol_max\", \"diff\", \"ave_price\", \"min_index\", \"max_index\"])\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "KGkBt-EpvHAE",
        "outputId": "80d7f279-543b-4e51-acda-7100877a6ab9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e0108b30c709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mave_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ave_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvol_max\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvol_min\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvol_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmin_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol_min\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmax_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vol\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_min\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mave_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exchanges = ['okx', 'binance', 'bybit', 'dydx']\n",
        "vol_size_kijun = 1000\n",
        "num_listed_ex_kijun = 4\n",
        "#read data\n",
        "ex_df = []\n",
        "for ex in exchanges:\n",
        "    data = pd.read_csv('/content/drive/My Drive/'+ex+'-prices.csv')\n",
        "    ex_df.append(data.drop(['Unnamed: 0'], axis=1))\n",
        "merged_df = pd.concat(ex_df, ignore_index=True)\n",
        "\n",
        "#add col for base, quote\n",
        "pair_list = []\n",
        "for ex_name in merged_df['ex_name'].unique():\n",
        "    df_ex = merged_df[merged_df['ex_name'] == ex_name]\n",
        "    for symbol in df_ex['symbol']:\n",
        "        base, quote = symbol.split('/')\n",
        "        pair_list.append({'ex_name': ex_name, 'base': base, 'quote': quote})\n",
        "pair_df = pd.DataFrame(pair_list)\n",
        "merged_df['base'] = pair_df['base']\n",
        "merged_df['quote'] = pair_df['quote']\n",
        "merged_df = check_ticker_in_multiple_exchanges(merged_df, num_listed_ex_kijun)\n",
        "merged_df['side'] = 'buy'\n",
        "#generate copied df for sell\n",
        "copied_df = merged_df.copy()\n",
        "copied_df['side'] = 'sell'\n",
        "base = copied_df['base']\n",
        "quote = copied_df['quote']\n",
        "copied_df['base'] = quote\n",
        "copied_df['quote'] = base\n",
        "copied_df['symbol'] = quote+'/'+base\n",
        "copied_df['ave_price'] = 1/copied_df['ave_price']\n",
        "total_df = pd.concat([merged_df, copied_df], ignore_index=True)\n",
        "total_df = total_df[total_df.vol > vol_size_kijun]\n",
        "total_df.reset_index(drop=True)\n",
        "#check all combinations available\n",
        "pair_combinations = check_all_combinations(list(total_df.base), list(total_df.quote))\n",
        "print('identified ', len(pair_combinations), ' pairs for arb.')\n",
        "#generate sync df\n",
        "sync_df = generate_df_for_pair_combinations(pair_combinations, list(total_df.ex_name), list(total_df.base), list(total_df.quote), list(total_df.ave_price), list(total_df.vol), list(total_df.side))\n",
        "final_df = pd.concat([total_df, sync_df], ignore_index=True).reset_index(drop=True)\n",
        "final_df[\"symbol\"] = final_df[\"symbol\"].str.replace(\"USDT|USDC|BUSD\", \"USD\", regex=True)\n",
        "final_df = final_df.sort_values(\"symbol\")\n",
        "#remove nan inf data rows\n",
        "nan_rows = final_df.loc[final_df.isna().any(axis=1)]\n",
        "print(len(nan_rows), ' rows contain nan and removed.')\n",
        "final_df = final_df.dropna()\n",
        "inf_rows = final_df.loc[final_df.isin([np.inf, -np.inf]).any(axis=1)]\n",
        "print(len(inf_rows), ' rows contain inf and removed.')\n",
        "final_df = final_df[~final_df.isin([np.inf, -np.inf]).any(axis=1)].dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HkAnLkNAvOSF",
        "outputId": "1838db12-c4a3-4679-d295-884839280140"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "identified  411592  pairs for arb.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-f9b5bfad6a87>:2: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"generate_df_for_pair_combinations\" failed type inference due to: No implementation of function Function(<class 'str'>) found for signature:\n",
            " \n",
            " >>> str(float64)\n",
            " \n",
            "There are 10 candidate implementations:\n",
            "   - Of which 10 did not match due to:\n",
            "   Overload of function 'str': File: <numerous>: Line N/A.\n",
            "     With argument(s): '(float64)':\n",
            "    No match.\n",
            "\n",
            "During: resolving callee type: Function(<class 'str'>)\n",
            "During: typing of call at <ipython-input-18-f9b5bfad6a87> (21)\n",
            "\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 21:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    <source elided>\n",
            "                              'ave_price': a_ave_price * b_ave_price,\n",
            "                              'vol': str(a_vol) + ',' + str(b_vol),\n",
            "                              ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-18-f9b5bfad6a87>:2: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"generate_df_for_pair_combinations\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 5:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    <source elided>\n",
            "    sync_data = []\n",
            "    for comb in pair_combinations:\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"generate_df_for_pair_combinations\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 4:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    sync_data = []\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 4:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    sync_data = []\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "<ipython-input-18-f9b5bfad6a87>:2: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"generate_df_for_pair_combinations\" failed type inference due to: non-precise type pyobject\n",
            "During: typing of argument at <ipython-input-18-f9b5bfad6a87> (5)\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 5:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    <source elided>\n",
            "    sync_data = []\n",
            "    for comb in pair_combinations:\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"generate_df_for_pair_combinations\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 5:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    <source elided>\n",
            "    sync_data = []\n",
            "    for comb in pair_combinations:\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-18-f9b5bfad6a87>\", line 5:\n",
            "def generate_df_for_pair_combinations(pair_combinations, ex_name, base, quote, ave_price, vol, side):\n",
            "    <source elided>\n",
            "    sync_data = []\n",
            "    for comb in pair_combinations:\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ex_name      symbol  ave_price                          vol  \\\n",
              "218011          okx,okx  1INCH/AAVE   0.006568  63125.493171,6183497.774172   \n",
              "256421      okx,binance  1INCH/AAVE   0.006567           2980.4519,474959.7   \n",
              "141909      binance,okx  1INCH/AAVE   0.006567           474959.7,2980.4519   \n",
              "142275  binance,binance  1INCH/AAVE   0.006568          6504938.4,145536.15   \n",
              "148984  binance,binance  1INCH/AAVE   0.006570          1151499.2,11069.942   \n",
              "...                 ...         ...        ...                          ...   \n",
              "243543          okx,okx     ZRX/ZIL   8.616583        2203000.099,66347.955   \n",
              "62117   binance,binance     ZRX/ZIL   8.602801            75541.0,2692965.0   \n",
              "61786   binance,binance     ZRX/ZIL   8.566210         1208472.0,13157879.0   \n",
              "40076       okx,binance     ZRX/ZIL   8.589041         66347.955,13157879.0   \n",
              "243583      okx,binance     ZRX/ZIL   8.593678        2203000.099,1208472.0   \n",
              "\n",
              "         base quote      side  \n",
              "218011  1INCH  AAVE  sell,buy  \n",
              "256421  1INCH  AAVE  sell,buy  \n",
              "141909  1INCH  AAVE  buy,sell  \n",
              "142275  1INCH  AAVE  buy,sell  \n",
              "148984  1INCH  AAVE  buy,sell  \n",
              "...       ...   ...       ...  \n",
              "243543    ZRX   ZIL  sell,buy  \n",
              "62117     ZRX   ZIL  buy,sell  \n",
              "61786     ZRX   ZIL  buy,sell  \n",
              "40076     ZRX   ZIL  buy,sell  \n",
              "243583    ZRX   ZIL  sell,buy  \n",
              "\n",
              "[413342 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e508ee15-09ea-45e8-95b5-cb353d21ed99\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ex_name</th>\n",
              "      <th>symbol</th>\n",
              "      <th>ave_price</th>\n",
              "      <th>vol</th>\n",
              "      <th>base</th>\n",
              "      <th>quote</th>\n",
              "      <th>side</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>218011</th>\n",
              "      <td>okx,okx</td>\n",
              "      <td>1INCH/AAVE</td>\n",
              "      <td>0.006568</td>\n",
              "      <td>63125.493171,6183497.774172</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>sell,buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256421</th>\n",
              "      <td>okx,binance</td>\n",
              "      <td>1INCH/AAVE</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>2980.4519,474959.7</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>sell,buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141909</th>\n",
              "      <td>binance,okx</td>\n",
              "      <td>1INCH/AAVE</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>474959.7,2980.4519</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142275</th>\n",
              "      <td>binance,binance</td>\n",
              "      <td>1INCH/AAVE</td>\n",
              "      <td>0.006568</td>\n",
              "      <td>6504938.4,145536.15</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148984</th>\n",
              "      <td>binance,binance</td>\n",
              "      <td>1INCH/AAVE</td>\n",
              "      <td>0.006570</td>\n",
              "      <td>1151499.2,11069.942</td>\n",
              "      <td>1INCH</td>\n",
              "      <td>AAVE</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243543</th>\n",
              "      <td>okx,okx</td>\n",
              "      <td>ZRX/ZIL</td>\n",
              "      <td>8.616583</td>\n",
              "      <td>2203000.099,66347.955</td>\n",
              "      <td>ZRX</td>\n",
              "      <td>ZIL</td>\n",
              "      <td>sell,buy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62117</th>\n",
              "      <td>binance,binance</td>\n",
              "      <td>ZRX/ZIL</td>\n",
              "      <td>8.602801</td>\n",
              "      <td>75541.0,2692965.0</td>\n",
              "      <td>ZRX</td>\n",
              "      <td>ZIL</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61786</th>\n",
              "      <td>binance,binance</td>\n",
              "      <td>ZRX/ZIL</td>\n",
              "      <td>8.566210</td>\n",
              "      <td>1208472.0,13157879.0</td>\n",
              "      <td>ZRX</td>\n",
              "      <td>ZIL</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40076</th>\n",
              "      <td>okx,binance</td>\n",
              "      <td>ZRX/ZIL</td>\n",
              "      <td>8.589041</td>\n",
              "      <td>66347.955,13157879.0</td>\n",
              "      <td>ZRX</td>\n",
              "      <td>ZIL</td>\n",
              "      <td>buy,sell</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243583</th>\n",
              "      <td>okx,binance</td>\n",
              "      <td>ZRX/ZIL</td>\n",
              "      <td>8.593678</td>\n",
              "      <td>2203000.099,1208472.0</td>\n",
              "      <td>ZRX</td>\n",
              "      <td>ZIL</td>\n",
              "      <td>sell,buy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>413342 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e508ee15-09ea-45e8-95b5-cb353d21ed99')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e508ee15-09ea-45e8-95b5-cb353d21ed99 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e508ee15-09ea-45e8-95b5-cb353d21ed99');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1 最初のdfにpairとして成立しているものの合成後のex list, sdie list, symbol, 価格を加える。\n",
        "2 全同一ペア同士の最大最小価格を比較する。\n",
        "'''\n",
        "@jit\n",
        "def compare_all_prices(pair_combinations, total_df):\n",
        "    sync_df = []\n",
        "    for comb in pair_combinations:\n",
        "        a_symbol = total_df.iloc[pair_combinations[0][0]]\n",
        "        b_symbol = total_df.iloc[pair_combinations[0][1]]\n",
        "        ex_name = a_symbol['ex_name'] + ','+b_symbol['ex_name']\n",
        "        symbol = check_sync_symbol(a_symbol['base'], a_symbol['quote'], b_symbol['base'], b_symbol['quote'])\n",
        "        ave_price = a_symbol['ave_price'] * b_symbol['ave_price']\n",
        "        sync_df.append({'ex_name':ex_name, 'symbol':symbol[0]+'/'+symbol[1], 'ave_price':ave_price, 'vol':str(a_symbol['vol'])+','+str(b_symbol['vol']) ,'base':symbol[0], 'quote':symbol[1], 'side':a_symbol['side']+','+b_symbol['side']})\n",
        "    sync_df = pd.DataFrame(sync_df)\n",
        "    return sync_df\n",
        "\n"
      ],
      "metadata": {
        "id": "DG0B2T5ugVUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CIDe1xXjgdO",
        "outputId": "12d87543-52b1-45e2-8ec1-b7a473d60c71"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  rows contain nan and removed.\n",
            "Minimum ave_price: 0.0\n",
            "Maximum ave_price: 2178649237.472767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symbols = list(final_df.symbol)\n",
        "symbols = list(set(symbols))\n",
        "\n",
        "arb_pair_data_list = []\n",
        "for s in symbols:\n",
        "    df = final_df.loc[final_df['symbol'] == s]\n",
        "    ind_min = df.ave_price.idxmin()\n",
        "    ind_max = df.ave_price.idxmax()\n",
        "    maxmin = max(df.ave_price) / min(df.ave_price) if min(df.ave_price) > 0 else 0\n",
        "    arb_pair_data_list.append({'symbol':s, 'ind_min':ind_min, 'ind_max':ind_max, 'max_min':maxmin})\n",
        "arb_pair_data_list"
      ],
      "metadata": {
        "id": "75RcUlCNgmz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def calculate_arb_pair_data(final_df, symbols):\n",
        "    arb_pair_data_list = []\n",
        "    for s in symbols:\n",
        "        df = final_df[final_df['symbol'] == s]\n",
        "        if len(df) == 0:\n",
        "            continue\n",
        "        ind_min = np.argmin(df['ave_price'].values)\n",
        "        ind_max = np.argmax(df['ave_price'].values)\n",
        "        max_price = np.max(df['ave_price'].values)\n",
        "        min_price = np.min(df['ave_price'].values)\n",
        "        maxmin = max_price / min_price if min_price > 0 else 0\n",
        "        arb_pair_data_list.append({'symbol': s, 'ind_min': ind_min, 'ind_max': ind_max, 'max_min': maxmin})\n",
        "    return arb_pair_data_list\n",
        "\n",
        "calculate_arb_pair_data(, symbols)"
      ],
      "metadata": {
        "id": "y1CyoEwRvg8D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "1345828b-e0bf-4c56-a593-faef67a737d9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypingError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-fd7485b4a262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marb_pair_data_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcalculate_arb_pair_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type array(pyobject, 2d, F)\nDuring: typing of argument at <ipython-input-53-fd7485b4a262> (3)\n\nFile \"<ipython-input-53-fd7485b4a262>\", line 3:\ndef calculate_arb_pair_data(final_df, symbols):\n    arb_pair_data_list = []\n    ^\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ex, base, quote, price\n",
        "'''\n",
        "@njit\n",
        "def compare_all_combination(df_index_n, base, quote, price):\n",
        "    #generate combination of df index\n",
        "    all_combinations = np.zeros((df_index_n**2, 2), dtype=np.int64)\n",
        "    i = 0\n",
        "    for x in range(df_index_n):\n",
        "        for y in range(df_index_n):\n",
        "            all_combinations[i, 0] = x\n",
        "            all_combinations[i, 1] = y\n",
        "            i += 1\n",
        "    #\n",
        "    pairs = []\n",
        "    for comb in all_combinations:\n",
        "        base_a = base[comb[0]]\n",
        "        quote_a = quote[comb[0]]\n",
        "        base_b = base[comb[1]]\n",
        "        quote_b = quote[comb[1]]\n",
        "        res = check_sync_symbol(base_a, quote_a, base_b, quote_b)\n",
        "        if res != ('',''):\n",
        "            pairs.append((comb[0],comb[1]))\n",
        "    return pairs\n",
        "\n",
        "pairs = compare_all_combination(6057, list(total_df.base), list(total_df.quote), list(total_df.ave_price))\n",
        "len(pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBhpuY1O2-S_",
        "outputId": "b4ebde33-b873-4990-908a-9c9d0f10ac4e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'base' of function 'compare_all_combination'.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"<ipython-input-9-2b57c81ed620>\", line 5:\n",
            "@njit\n",
            "def compare_all_combination(df_index_n, base, quote, price):\n",
            "^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'price' of function 'compare_all_combination'.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"<ipython-input-9-2b57c81ed620>\", line 5:\n",
            "@njit\n",
            "def compare_all_combination(df_index_n, base, quote, price):\n",
            "^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
            "/usr/local/lib/python3.9/dist-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'quote' of function 'compare_all_combination'.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"<ipython-input-9-2b57c81ed620>\", line 5:\n",
            "@njit\n",
            "def compare_all_combination(df_index_n, base, quote, price):\n",
            "^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "396224"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df['test'] = total_df.quote+'/'+total_df.base"
      ],
      "metadata": {
        "id": "WSPIOsVe8NBk"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "50Zgugh9tZlb",
        "outputId": "a8af9a05-ade1-4741-dc14-22db5a5ac89b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     ex_name     symbol  ave_price           vol   base quote  side       test\n",
              "0        okx    BCD/BTC   0.000007  2.547421e+04    BCD   BTC   buy    BTC/BCD\n",
              "1        okx  LUNA/USDC   1.423750  3.285728e+05   LUNA  USDC   buy  USDC/LUNA\n",
              "2        okx   LINK/BTC   0.000280  3.717639e+04   LINK   BTC   buy   BTC/LINK\n",
              "3        okx    NEO/BTC   0.000463  6.105353e+03    NEO   BTC   buy    BTC/NEO\n",
              "4        okx   NULS/BTC   0.000011  5.780933e+04   NULS   BTC   buy   BTC/NULS\n",
              "...      ...        ...        ...           ...    ...   ...   ...        ...\n",
              "2473    dydx    ZEC/USD  35.450000  6.438192e+06    ZEC   USD  sell    USD/ZEC\n",
              "2474    dydx    SOL/USD  20.455500  5.539325e+07    SOL   USD  sell    USD/SOL\n",
              "2475    dydx  SUSHI/USD   1.233500  8.610171e+06  SUSHI   USD  sell  USD/SUSHI\n",
              "2476    dydx    ICP/USD   5.375000  4.724167e+06    ICP   USD  sell    USD/ICP\n",
              "2477    dydx    CRV/USD   0.980850  7.917155e+06    CRV   USD  sell    USD/CRV\n",
              "\n",
              "[1750 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79ca9f23-5ac6-44d7-ab0a-daae5a694255\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ex_name</th>\n",
              "      <th>symbol</th>\n",
              "      <th>ave_price</th>\n",
              "      <th>vol</th>\n",
              "      <th>base</th>\n",
              "      <th>quote</th>\n",
              "      <th>side</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>okx</td>\n",
              "      <td>BCD/BTC</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>2.547421e+04</td>\n",
              "      <td>BCD</td>\n",
              "      <td>BTC</td>\n",
              "      <td>buy</td>\n",
              "      <td>BTC/BCD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>okx</td>\n",
              "      <td>LUNA/USDC</td>\n",
              "      <td>1.423750</td>\n",
              "      <td>3.285728e+05</td>\n",
              "      <td>LUNA</td>\n",
              "      <td>USDC</td>\n",
              "      <td>buy</td>\n",
              "      <td>USDC/LUNA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>okx</td>\n",
              "      <td>LINK/BTC</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>3.717639e+04</td>\n",
              "      <td>LINK</td>\n",
              "      <td>BTC</td>\n",
              "      <td>buy</td>\n",
              "      <td>BTC/LINK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>okx</td>\n",
              "      <td>NEO/BTC</td>\n",
              "      <td>0.000463</td>\n",
              "      <td>6.105353e+03</td>\n",
              "      <td>NEO</td>\n",
              "      <td>BTC</td>\n",
              "      <td>buy</td>\n",
              "      <td>BTC/NEO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>okx</td>\n",
              "      <td>NULS/BTC</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>5.780933e+04</td>\n",
              "      <td>NULS</td>\n",
              "      <td>BTC</td>\n",
              "      <td>buy</td>\n",
              "      <td>BTC/NULS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>dydx</td>\n",
              "      <td>ZEC/USD</td>\n",
              "      <td>35.450000</td>\n",
              "      <td>6.438192e+06</td>\n",
              "      <td>ZEC</td>\n",
              "      <td>USD</td>\n",
              "      <td>sell</td>\n",
              "      <td>USD/ZEC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>dydx</td>\n",
              "      <td>SOL/USD</td>\n",
              "      <td>20.455500</td>\n",
              "      <td>5.539325e+07</td>\n",
              "      <td>SOL</td>\n",
              "      <td>USD</td>\n",
              "      <td>sell</td>\n",
              "      <td>USD/SOL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>dydx</td>\n",
              "      <td>SUSHI/USD</td>\n",
              "      <td>1.233500</td>\n",
              "      <td>8.610171e+06</td>\n",
              "      <td>SUSHI</td>\n",
              "      <td>USD</td>\n",
              "      <td>sell</td>\n",
              "      <td>USD/SUSHI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>dydx</td>\n",
              "      <td>ICP/USD</td>\n",
              "      <td>5.375000</td>\n",
              "      <td>4.724167e+06</td>\n",
              "      <td>ICP</td>\n",
              "      <td>USD</td>\n",
              "      <td>sell</td>\n",
              "      <td>USD/ICP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>dydx</td>\n",
              "      <td>CRV/USD</td>\n",
              "      <td>0.980850</td>\n",
              "      <td>7.917155e+06</td>\n",
              "      <td>CRV</td>\n",
              "      <td>USD</td>\n",
              "      <td>sell</td>\n",
              "      <td>USD/CRV</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1750 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79ca9f23-5ac6-44d7-ab0a-daae5a694255')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79ca9f23-5ac6-44d7-ab0a-daae5a694255 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79ca9f23-5ac6-44d7-ab0a-daae5a694255');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pair_combinations = []\n",
        "for i in range(len(combination_list)):\n",
        "    base_a = total_df.iloc[combination_list[i][0]].base\n",
        "    quote_a = total_df.iloc[combination_list[i][0]].quote\n",
        "    base_b = total_df.iloc[combination_list[i][1]].base\n",
        "    quote_b = total_df.iloc[combination_list[i][1]].quote\n",
        "    pair = check_sync_symbol(base_a, quote_a, base_b, quote_b)\n",
        "    if pair != ('',''):\n",
        "        pair_combinations.append(combination_list[i])\n",
        "        #print(total_df.iloc[d[i][0]].symbol, ' x ', total_df.iloc[d[i][1]].symbol, ' = ', pair)\n",
        "print('detected ', len(pair_combinations), ' pairs.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "8DLD5fh999pd",
        "outputId": "1cb64d8b-4c9a-4562-e65f-859c8ca42e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d5a6c6546a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbase_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mquote_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mbase_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mquote_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1568\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3381\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3382\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3383\u001b[0;31m             result = self._constructor_sliced(\n\u001b[0m\u001b[1;32m   3384\u001b[0m                 \u001b[0mnew_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3385\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_extract_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0;31m# gh-17261\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mis_empty_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m     \"\"\"\n\u001b[1;32m    782\u001b[0m     \u001b[0mUtility\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0minstantiated\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@njit\n",
        "def generate_combinations(n):\n",
        "    result = np.zeros((n**2, 2), dtype=np.int64)\n",
        "    i = 0\n",
        "    for x in range(n):\n",
        "        for y in range(n):\n",
        "            result[i, 0] = x\n",
        "            result[i, 1] = y\n",
        "            i += 1\n",
        "    return result\n",
        "\n",
        "comb = generate_combinations(6000)\n",
        "len(comb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkiSNRaXswv5",
        "outputId": "ced42d55-1672-480b-f926-f9ba7464f838"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36000000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KAtgZpev7_I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}